---
title: "Impressions of Abadi et al. (2019)"
author: Brian O'Meara
output: md_document
---

The recent article by [Abadi et al. (2019)](https://doi.org/10.1038/s41467-019-08822-w) argues that model selection is unnecessary, and that we should use the most complex model, GTR+I+G. This seems a bit too good to be true (for one thing, there are many more complex models than this -- DNA evolution can probably be described by more than six free parameters; for another, there is heterogeneity across genes that may be fit by partitioned models). I decided to dig into their results some more. They are great about having their scripts and data files available, though I could not easily find the trees used for generation of sequences. I did some quick analyses of their data, focusing on their c3 dataset (the most realistic model) and their empirical trees. Note for speed I'm initially using just a subset of their trees, but will do more after playing with this some more.

My first impression on looking at some of their data was that their empirical trees were rather small: models might work fine for a seven taxon tree, for example, but might not scale well. Their trees came from [PlantDB](http://www.plantgdb.org/), [Selectome](https://selectome.unil.ch/), and [PANDIT](https://www.ebi.ac.uk/research/goldman/software/pandit), which are particular databases that don't necessarily represent the trees used by most comparative biologists (for example, PANDIT has not been updated in 14 years). Thus, their results may be perfectly correct for trees in these databases, but should not be comforting to systematists who want to use DNA models for multiple species. As an independent source of these trees, I turned to Open Tree of Life, which has a database of over 4,000 trees deposited by systematists and other biologists.

```{r summary, echo=FALSE, message=FALSE, warning=FALSE}
 drake::loadd(empirical_summary)
 drake::loadd(c3_tree_summary)
 drake::loadd(otol_summary)
 # otol_density <- density(otol_summary$ntax, na.rm=TRUE)
 # otol_density$y <- otol_density$y/sum(otol_density$y)
 # empirical_density <- density(empirical_summary$ntax, na.rm=TRUE)
 # empirical_density$y <- empirical_density$y/sum(empirical_density$y)
 density_info <- data.frame(Number_of_taxa = c(otol_summary$ntax, empirical_summary$ntax), Source=c(rep("Open Tree of Life", nrow(otol_summary)), rep("Abadi et al. empirical", nrow(empirical_summary))))
```

Number of taxa in trees in Open Tree Of Life database (one per study) and number of taxa on Abadi et al. (2019). The median number of taxa in the Abadi et al. empirical trees was `r round(median(empirical_summary$ntax, na.rm=TRUE),1)` (`r round(quantile(empirical_summary$ntax, probs=c(0.025, .975),na.rm=TRUE),1)`), while the median number in Open Tree of Life was `r round(median(otol_summary$ntax, na.rm=TRUE),1)` (`r round(quantile(otol_summary$ntax, probs=c(0.025, .975),na.rm=TRUE),1)`) [numbers in parentheses are the 95% range of trees].

```{r summary1, echo=FALSE, message=FALSE, fig.width=12, fig.height=12, warning=FALSE}
# plot(x=range(c(otol_density$x, empirical_density$x)), y=range(c(otol_density$y, empirical_density$y)), type="n", log="x", xlab="Number of taxa", ylab="Proportion of trees", bty="n")
# lines(otol_density, col="red")
# lines(empirical_density, col="black")
p <- ggplot(density_info, aes(x=Number_of_taxa, fill=Source)) + geom_density(alpha=.2) + scale_x_continuous(trans='log10')
p
```

The data set sizes are small, too. Here are the number of taxa and number of sites (`r round(median(empirical_summary$nsites, na.rm=TRUE),1)` (`r round(quantile(empirical_summary$nsites, probs=c(0.025, .975),na.rm=TRUE),1)`)).

```{r scatterplot, echo=FALSE, message=FALSE, fig.width=12, fig.height=12, warning=FALSE}
p <- ggplot(empirical_summary, aes(x=nsites, y=ntax)) + geom_count()
p
```

We can also compare Robinson-Foulds distances of trees from different tree inference methods and models with those from GTR+I+G with the full dataset (since I couldn't find the "true tree", I'm using distance to the tree with the best model as a measure of how good these other models are). If that model is good enough without having to select, then maybe things like UPGMA are good enough, or trees using fewer characters (just 100 and 250 characters, for example). Based on these results, you sacrifice something by giving up models entirely to use BioNJ or to have small datasets, but not much -- even though in reality we work hard to get large datasets and use somewhat realistic models.

```{r summary2, echo=FALSE, message=FALSE, fig.width=12, fig.height=12, warning=FALSE}
treetree_distances <- data.frame(distance = c(c3_tree_summary$g_b, c3_tree_summary$g_u, c3_tree_summary$g_jc, c3_tree_summary$g_g100, c3_tree_summary$g_g250), approach=c(rep("BioNJ", nrow(c3_tree_summary)), rep("UPGMA", nrow(c3_tree_summary)), rep("Jukes-Cantor", nrow(c3_tree_summary)), rep("GTR+I+G 100 sites", nrow(c3_tree_summary)), rep("GTR+I+G 250 sites", nrow(c3_tree_summary))))
p <- ggplot(treetree_distances, aes(x=approach, y=distance)) +
  geom_violin(trim=FALSE) + stat_summary(fun.data=mean_sdl, geom="pointrange", color="red")
p
```

It certainly seems that some models
